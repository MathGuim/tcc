{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f0d4867d710>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "torch.manual_seed(360);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting to download data...\nStarting to extract data...\nData has been downloaded and extracted to ../data/raw/.\n"
    }
   ],
   "source": [
    "def download_and_extract_data(dataset_dir='datasets'):\n",
    "    data_zip = os.path.join(dataset_dir, 'hymenoptera_data.zip')\n",
    "    data_path = os.path.join(dataset_dir, 'hymenoptera_data')\n",
    "    url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        if not os.path.exists(data_zip):\n",
    "            print(\"Starting to download data...\")\n",
    "            data = request.urlopen(url, timeout=15).read()\n",
    "            with open(data_zip, 'wb') as f:\n",
    "                f.write(data)\n",
    "\n",
    "        print(\"Starting to extract data...\")\n",
    "        with ZipFile(data_zip, 'r') as zip_f:\n",
    "            zip_f.extractall(dataset_dir)\n",
    "        \n",
    "    print(\"Data has been downloaded and extracted to {}.\".format(dataset_dir))\n",
    "    \n",
    "download_and_extract_data('../data/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw/hymenoptera_data'\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train'), train_transforms)\n",
    "val_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'val'), val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "lrscheduler = LRScheduler(policy='StepLR', step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Checkpoint\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    "    f_params='best_model.pt', monitor='valid_acc_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Freezer\n",
    "\n",
    "freezer = Freezer(lambda x: not x.startswith('model.fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel, \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.001,\n",
    "    batch_size=4,\n",
    "    max_epochs=25,\n",
    "    module__output_features=2,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__momentum=0.9,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=4,\n",
    "    iterator_valid__shuffle=True,\n",
    "    iterator_valid__num_workers=4,\n",
    "    train_split=predefined_split(val_ds),\n",
    "    callbacks=[lrscheduler, checkpoint, freezer],\n",
    "    device='cuda' # comment to train on cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/matheusguim/.cache/torch/checkpoints/resnet18-5c106cde.pth\n100%|██████████| 44.7M/44.7M [00:09<00:00, 4.81MB/s]\n  epoch    train_loss    valid_acc    valid_loss    cp      dur\n-------  ------------  -----------  ------------  ----  -------\n      1        \u001b[36m0.6321\u001b[0m       \u001b[32m0.8954\u001b[0m        \u001b[35m0.2665\u001b[0m     +  10.7125\n      2        \u001b[36m0.5036\u001b[0m       0.8497        0.3550        7.7381\n      3        \u001b[36m0.4133\u001b[0m       \u001b[32m0.9281\u001b[0m        \u001b[35m0.2334\u001b[0m     +  7.7809\n      4        \u001b[36m0.3411\u001b[0m       \u001b[32m0.9412\u001b[0m        \u001b[35m0.1871\u001b[0m     +  7.9085\n      5        0.4514       0.8627        0.3128        7.6515\n      6        0.4206       0.9020        0.2500        7.6331\n      7        0.4306       \u001b[32m0.9542\u001b[0m        \u001b[35m0.1625\u001b[0m     +  7.7217\n      8        0.5042       0.9412        0.2440        7.1988\n      9        \u001b[36m0.3114\u001b[0m       0.9412        0.2066        7.6622\n     10        0.3866       0.9542        0.1772        7.8043\n     11        0.3929       0.9477        0.1825        7.8265\n     12        0.3362       0.9412        0.1848        7.7408\n     13        0.4479       0.9346        0.2036        7.8258\n     14        0.3514       0.9281        0.2091        7.7065\n     15        0.3613       0.9477        0.1803        7.8514\n     16        0.3550       0.9281        0.2083        7.6218\n     17        \u001b[36m0.3113\u001b[0m       0.9412        0.1949        6.6134\n     18        0.3160       0.9542        0.2006        7.5222\n     19        0.3676       0.9477        0.2001        7.4210\n     20        \u001b[36m0.2837\u001b[0m       0.9216        0.2060        7.5471\n     21        0.4275       0.9477        0.1917        7.5656\n     22        \u001b[36m0.2816\u001b[0m       0.9085        0.2504        7.9043\n     23        0.3389       0.9477        0.1854        7.7995\n     24        0.3014       0.9412        0.1923        7.7014\n     25        \u001b[36m0.2758\u001b[0m       0.9477        0.1912        7.7710\n"
    }
   ],
   "source": [
    "net.fit(train_ds, y=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bittccconda9cbe7146dfc24b9484b2f8419dc5035c",
   "display_name": "Python 3.8.3 64-bit ('tcc': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}