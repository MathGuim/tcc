{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Status  Seniority   Home  Time  Age  Marital  Records        Job  \\\n0      good          9   rent    60   30  married   no_rec  freelance   \n1      good         17   rent    60   58    widow   no_rec      fixed   \n2       bad         10  owner    36   46  married  yes_rec  freelance   \n3      good          0   rent    60   24   single   no_rec      fixed   \n4      good          0   rent    36   26   single   no_rec      fixed   \n...     ...        ...    ...   ...  ...      ...      ...        ...   \n4441    bad          1   rent    60   39  married   no_rec      fixed   \n4442   good         22  owner    60   46  married   no_rec      fixed   \n4443    bad          0  owner    24   37  married   no_rec    partime   \n4444   good          0   rent    48   23   single   no_rec  freelance   \n4445   good          5  owner    60   32  married   no_rec  freelance   \n\n      Expenses  Income  ...         timeR         ageR       expensesR  \\\n0           73     129  ...  time (48,99]  age (25,30]     exp (60,80]   \n1           48     131  ...  time (48,99]  age (50,99]     exp (40,50]   \n2           90     200  ...  time (24,36]  age (40,50]  exp (80,1e+04]   \n3           63     182  ...  time (48,99]   age (0,25]     exp (60,80]   \n4           46     107  ...  time (24,36]  age (25,30]     exp (40,50]   \n...        ...     ...  ...           ...          ...             ...   \n4441        69      92  ...  time (48,99]  age (30,40]     exp (60,80]   \n4442        60      75  ...  time (48,99]  age (40,50]     exp (50,60]   \n4443        60      90  ...  time (12,24]  age (30,40]     exp (50,60]   \n4444        49     140  ...  time (36,48]   age (0,25]     exp (40,50]   \n4445        60     140  ...  time (48,99]  age (30,40]     exp (50,60]   \n\n              incomeR              assetsR               debtR  \\\n0       inc (110,140]         asset (-1,0]         debt (-1,0]   \n1       inc (110,140]         asset (-1,0]         debt (-1,0]   \n2     inc (190,1e+04]      asset (0,3e+03]         debt (-1,0]   \n3       inc (140,190]      asset (0,3e+03]         debt (-1,0]   \n4        inc (80,110]         asset (-1,0]         debt (-1,0]   \n...               ...                  ...                 ...   \n4441     inc (80,110]         asset (-1,0]         debt (-1,0]   \n4442       inc (0,80]      asset (0,3e+03]  debt (500,1.5e+03]   \n4443     inc (80,110]  asset (3e+03,5e+03]         debt (-1,0]   \n4444    inc (110,140]         asset (-1,0]         debt (-1,0]   \n4445    inc (110,140]  asset (3e+03,5e+03]  debt (500,1.5e+03]   \n\n                   amountR                  priceR        finratR    savingsR  \n0             am (600,900]          priz (0,1e+03]  finr (90,100]   sav (4,6]  \n1         am (900,1.1e+03]  priz (1.5e+03,1.8e+03]   finr (50,70]   sav (4,6]  \n2       am (1.4e+03,1e+05]    priz (1.8e+03,1e+05]   finr (50,70]   sav (0,2]  \n3             am (600,900]  priz (1.3e+03,1.5e+03]   finr (50,70]  sav (6,99]  \n4               am (0,600]          priz (0,1e+03]    finr (0,50]  sav (6,99]  \n...                    ...                     ...            ...         ...  \n4441          am (600,900]    priz (1e+03,1.3e+03]   finr (80,90]   sav (0,2]  \n4442      am (900,1.1e+03]    priz (1e+03,1.3e+03]   finr (70,80]   sav (0,2]  \n4443            am (0,600]          priz (0,1e+03]   finr (50,70]   sav (0,2]  \n4444            am (0,600]          priz (0,1e+03]  finr (90,100]  sav (6,99]  \n4445  am (1.1e+03,1.4e+03]  priz (1.5e+03,1.8e+03]   finr (80,90]   sav (2,4]  \n\n[4446 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Status</th>\n      <th>Seniority</th>\n      <th>Home</th>\n      <th>Time</th>\n      <th>Age</th>\n      <th>Marital</th>\n      <th>Records</th>\n      <th>Job</th>\n      <th>Expenses</th>\n      <th>Income</th>\n      <th>...</th>\n      <th>timeR</th>\n      <th>ageR</th>\n      <th>expensesR</th>\n      <th>incomeR</th>\n      <th>assetsR</th>\n      <th>debtR</th>\n      <th>amountR</th>\n      <th>priceR</th>\n      <th>finratR</th>\n      <th>savingsR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>good</td>\n      <td>9</td>\n      <td>rent</td>\n      <td>60</td>\n      <td>30</td>\n      <td>married</td>\n      <td>no_rec</td>\n      <td>freelance</td>\n      <td>73</td>\n      <td>129</td>\n      <td>...</td>\n      <td>time (48,99]</td>\n      <td>age (25,30]</td>\n      <td>exp (60,80]</td>\n      <td>inc (110,140]</td>\n      <td>asset (-1,0]</td>\n      <td>debt (-1,0]</td>\n      <td>am (600,900]</td>\n      <td>priz (0,1e+03]</td>\n      <td>finr (90,100]</td>\n      <td>sav (4,6]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>good</td>\n      <td>17</td>\n      <td>rent</td>\n      <td>60</td>\n      <td>58</td>\n      <td>widow</td>\n      <td>no_rec</td>\n      <td>fixed</td>\n      <td>48</td>\n      <td>131</td>\n      <td>...</td>\n      <td>time (48,99]</td>\n      <td>age (50,99]</td>\n      <td>exp (40,50]</td>\n      <td>inc (110,140]</td>\n      <td>asset (-1,0]</td>\n      <td>debt (-1,0]</td>\n      <td>am (900,1.1e+03]</td>\n      <td>priz (1.5e+03,1.8e+03]</td>\n      <td>finr (50,70]</td>\n      <td>sav (4,6]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bad</td>\n      <td>10</td>\n      <td>owner</td>\n      <td>36</td>\n      <td>46</td>\n      <td>married</td>\n      <td>yes_rec</td>\n      <td>freelance</td>\n      <td>90</td>\n      <td>200</td>\n      <td>...</td>\n      <td>time (24,36]</td>\n      <td>age (40,50]</td>\n      <td>exp (80,1e+04]</td>\n      <td>inc (190,1e+04]</td>\n      <td>asset (0,3e+03]</td>\n      <td>debt (-1,0]</td>\n      <td>am (1.4e+03,1e+05]</td>\n      <td>priz (1.8e+03,1e+05]</td>\n      <td>finr (50,70]</td>\n      <td>sav (0,2]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>good</td>\n      <td>0</td>\n      <td>rent</td>\n      <td>60</td>\n      <td>24</td>\n      <td>single</td>\n      <td>no_rec</td>\n      <td>fixed</td>\n      <td>63</td>\n      <td>182</td>\n      <td>...</td>\n      <td>time (48,99]</td>\n      <td>age (0,25]</td>\n      <td>exp (60,80]</td>\n      <td>inc (140,190]</td>\n      <td>asset (0,3e+03]</td>\n      <td>debt (-1,0]</td>\n      <td>am (600,900]</td>\n      <td>priz (1.3e+03,1.5e+03]</td>\n      <td>finr (50,70]</td>\n      <td>sav (6,99]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>0</td>\n      <td>rent</td>\n      <td>36</td>\n      <td>26</td>\n      <td>single</td>\n      <td>no_rec</td>\n      <td>fixed</td>\n      <td>46</td>\n      <td>107</td>\n      <td>...</td>\n      <td>time (24,36]</td>\n      <td>age (25,30]</td>\n      <td>exp (40,50]</td>\n      <td>inc (80,110]</td>\n      <td>asset (-1,0]</td>\n      <td>debt (-1,0]</td>\n      <td>am (0,600]</td>\n      <td>priz (0,1e+03]</td>\n      <td>finr (0,50]</td>\n      <td>sav (6,99]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4441</th>\n      <td>bad</td>\n      <td>1</td>\n      <td>rent</td>\n      <td>60</td>\n      <td>39</td>\n      <td>married</td>\n      <td>no_rec</td>\n      <td>fixed</td>\n      <td>69</td>\n      <td>92</td>\n      <td>...</td>\n      <td>time (48,99]</td>\n      <td>age (30,40]</td>\n      <td>exp (60,80]</td>\n      <td>inc (80,110]</td>\n      <td>asset (-1,0]</td>\n      <td>debt (-1,0]</td>\n      <td>am (600,900]</td>\n      <td>priz (1e+03,1.3e+03]</td>\n      <td>finr (80,90]</td>\n      <td>sav (0,2]</td>\n    </tr>\n    <tr>\n      <th>4442</th>\n      <td>good</td>\n      <td>22</td>\n      <td>owner</td>\n      <td>60</td>\n      <td>46</td>\n      <td>married</td>\n      <td>no_rec</td>\n      <td>fixed</td>\n      <td>60</td>\n      <td>75</td>\n      <td>...</td>\n      <td>time (48,99]</td>\n      <td>age (40,50]</td>\n      <td>exp (50,60]</td>\n      <td>inc (0,80]</td>\n      <td>asset (0,3e+03]</td>\n      <td>debt (500,1.5e+03]</td>\n      <td>am (900,1.1e+03]</td>\n      <td>priz (1e+03,1.3e+03]</td>\n      <td>finr (70,80]</td>\n      <td>sav (0,2]</td>\n    </tr>\n    <tr>\n      <th>4443</th>\n      <td>bad</td>\n      <td>0</td>\n      <td>owner</td>\n      <td>24</td>\n      <td>37</td>\n      <td>married</td>\n      <td>no_rec</td>\n      <td>partime</td>\n      <td>60</td>\n      <td>90</td>\n      <td>...</td>\n      <td>time (12,24]</td>\n      <td>age (30,40]</td>\n      <td>exp (50,60]</td>\n      <td>inc (80,110]</td>\n      <td>asset (3e+03,5e+03]</td>\n      <td>debt (-1,0]</td>\n      <td>am (0,600]</td>\n      <td>priz (0,1e+03]</td>\n      <td>finr (50,70]</td>\n      <td>sav (0,2]</td>\n    </tr>\n    <tr>\n      <th>4444</th>\n      <td>good</td>\n      <td>0</td>\n      <td>rent</td>\n      <td>48</td>\n      <td>23</td>\n      <td>single</td>\n      <td>no_rec</td>\n      <td>freelance</td>\n      <td>49</td>\n      <td>140</td>\n      <td>...</td>\n      <td>time (36,48]</td>\n      <td>age (0,25]</td>\n      <td>exp (40,50]</td>\n      <td>inc (110,140]</td>\n      <td>asset (-1,0]</td>\n      <td>debt (-1,0]</td>\n      <td>am (0,600]</td>\n      <td>priz (0,1e+03]</td>\n      <td>finr (90,100]</td>\n      <td>sav (6,99]</td>\n    </tr>\n    <tr>\n      <th>4445</th>\n      <td>good</td>\n      <td>5</td>\n      <td>owner</td>\n      <td>60</td>\n      <td>32</td>\n      <td>married</td>\n      <td>no_rec</td>\n      <td>freelance</td>\n      <td>60</td>\n      <td>140</td>\n      <td>...</td>\n      <td>time (48,99]</td>\n      <td>age (30,40]</td>\n      <td>exp (50,60]</td>\n      <td>inc (110,140]</td>\n      <td>asset (3e+03,5e+03]</td>\n      <td>debt (500,1.5e+03]</td>\n      <td>am (1.1e+03,1.4e+03]</td>\n      <td>priz (1.5e+03,1.8e+03]</td>\n      <td>finr (80,90]</td>\n      <td>sav (2,4]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4446 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('../data/raw/CleanCreditScoring.csv').drop(columns='Assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "  def __init__(self, data, cat_cols=None, output_col=None):\n",
    "    \"\"\"\n",
    "    Characterizes a Dataset for PyTorch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data: pandas data frame\n",
    "      The data frame object for the input data. It must\n",
    "      contain all the continuous, categorical and the\n",
    "      output columns to be used.\n",
    "\n",
    "    cat_cols: List of strings\n",
    "      The names of the categorical columns in the data.\n",
    "      These columns will be passed through the embedding\n",
    "      layers in the model. These columns must be\n",
    "      label encoded beforehand. \n",
    "\n",
    "    output_col: string\n",
    "      The name of the output variable column in the data\n",
    "      provided.\n",
    "    \"\"\"\n",
    "\n",
    "    self.n = data.shape[0]\n",
    "\n",
    "    if output_col:\n",
    "      self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)\n",
    "    else:\n",
    "      self.y =  np.zeros((self.n, 1))\n",
    "\n",
    "    self.cat_cols = cat_cols if cat_cols else []\n",
    "    self.cont_cols = [col for col in data.columns\n",
    "                      if col not in self.cat_cols + [output_col]]\n",
    "\n",
    "    if self.cont_cols:\n",
    "      self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
    "    else:\n",
    "      self.cont_X = np.zeros((self.n, 1))\n",
    "\n",
    "    if self.cat_cols:\n",
    "      self.cat_X = data[cat_cols].astype(np.int64).values\n",
    "    else:\n",
    "      self.cat_X =  np.zeros((self.n, 1))\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    Denotes the total number of samples.\n",
    "    \"\"\"\n",
    "    return self.n\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    Generates one sample of data.\n",
    "    \"\"\"\n",
    "    return [self.y[idx], self.cont_X[idx], self.cat_X[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "  def __init__(self, emb_dims, no_of_cont, lin_layer_sizes,\n",
    "               output_size, emb_dropout, lin_layer_dropouts):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    emb_dims: List of two element tuples\n",
    "      This list will contain a two element tuple for each\n",
    "      categorical feature. The first element of a tuple will\n",
    "      denote the number of unique values of the categorical\n",
    "      feature. The second element will denote the embedding\n",
    "      dimension to be used for that feature.\n",
    "\n",
    "    no_of_cont: Integer\n",
    "      The number of continuous features in the data.\n",
    "\n",
    "    lin_layer_sizes: List of integers.\n",
    "      The size of each linear layer. The length will be equal\n",
    "      to the total number\n",
    "      of linear layers in the network.\n",
    "\n",
    "    output_size: Integer\n",
    "      The size of the final output.\n",
    "\n",
    "    emb_dropout: Float\n",
    "      The dropout to be used after the embedding layers.\n",
    "\n",
    "    lin_layer_dropouts: List of floats\n",
    "      The dropouts to be used after each linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # Embedding layers\n",
    "    self.emb_layers = nn.ModuleList([nn.Embedding(x, y)\n",
    "                                     for x, y in emb_dims])\n",
    "\n",
    "    no_of_embs = sum([y for x, y in emb_dims])\n",
    "    self.no_of_embs = no_of_embs\n",
    "    self.no_of_cont = no_of_cont\n",
    "\n",
    "    # Linear Layers\n",
    "    first_lin_layer = nn.Linear(self.no_of_embs + self.no_of_cont,\n",
    "                                lin_layer_sizes[0])\n",
    "\n",
    "    self.lin_layers =\\\n",
    "     nn.ModuleList([first_lin_layer] +\\\n",
    "          [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\n",
    "           for i in range(len(lin_layer_sizes) - 1)])\n",
    "    \n",
    "    for lin_layer in self.lin_layers:\n",
    "      nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "\n",
    "    # Output Layer\n",
    "    self.output_layer = nn.Linear(lin_layer_sizes[-1],\n",
    "                                  output_size)\n",
    "    nn.init.kaiming_normal_(self.output_layer.weight.data)\n",
    "\n",
    "    # Batch Norm Layers\n",
    "    self.first_bn_layer = nn.BatchNorm1d(self.no_of_cont)\n",
    "    self.bn_layers = nn.ModuleList([nn.BatchNorm1d(size)\n",
    "                                    for size in lin_layer_sizes])\n",
    "\n",
    "    # Dropout Layers\n",
    "    self.emb_dropout_layer = nn.Dropout(emb_dropout)\n",
    "    self.droput_layers = nn.ModuleList([nn.Dropout(size)\n",
    "                                  for size in lin_layer_dropouts])\n",
    "\n",
    "  def forward(self, cont_data, cat_data):\n",
    "\n",
    "    if self.no_of_embs != 0:\n",
    "      x = [emb_layer(cat_data[:, i])\n",
    "           for i,emb_layer in enumerate(self.emb_layers)]\n",
    "      x = torch.cat(x, 1)\n",
    "      x = self.emb_dropout_layer(x)\n",
    "\n",
    "    if self.no_of_cont != 0:\n",
    "      normalized_cont_data = self.first_bn_layer(cont_data)\n",
    "\n",
    "      if self.no_of_embs != 0:\n",
    "        x = torch.cat([x, normalized_cont_data], 1) \n",
    "      else:\n",
    "        x = normalized_cont_data\n",
    "\n",
    "    for lin_layer, dropout_layer, bn_layer in\\\n",
    "        zip(self.lin_layers, self.droput_layers, self.bn_layers):\n",
    "      \n",
    "      x = F.relu(lin_layer(x))\n",
    "      x = bn_layer(x)\n",
    "      x = dropout_layer(x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../data/raw/train.csv\", usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\", \"YearBuilt\"]\n",
    "output_feature = \"SalePrice\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoders = {}\n",
    "for cat_col in categorical_features:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data[cat_col] = label_encoders[cat_col].fit_transform(data[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularDataset(data=data, cat_cols=categorical_features,output_col=output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "dataloader = DataLoader(dataset, batchsize, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = [int(data[col].nunique()) for col in categorical_features]\n",
    "emb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeedForwardNN(emb_dims, no_of_cont=4, lin_layer_sizes=[50, 100],\n",
    "                          output_size=1, emb_dropout=0.04,\n",
    "                          lin_layer_dropouts=[0.001,0.01]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "no_of_epochs = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "for epoch in range(no_of_epochs):\n",
    "    for y, cont_x, cat_x in dataloader:\n",
    "          \n",
    "        cat_x = cat_x.to(device)\n",
    "        cont_x = cont_x.to(device)\n",
    "        y  = y.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        preds = model(cont_x, cat_x)\n",
    "        #print(preds - y)\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(4.4264e+08, device='cuda:0', grad_fn=<MseLossBackward>)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}